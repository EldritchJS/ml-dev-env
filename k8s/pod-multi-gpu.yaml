apiVersion: v1
kind: Pod
metadata:
  name: ml-dev-env
  namespace: nccl-test
  labels:
    app: ml-dev-env
    pytorch-version: "2.9"
    numpy-version: "2.2.6"
  annotations:
    description: "Multi-GPU ML development environment with RDMA support - PyTorch 2.9 + NumPy 2.x"
spec:
  # Use host network for RDMA/InfiniBand access (disabled for now to fix CUDA libraries)
  # hostNetwork: true
  # hostIPC: true

  restartPolicy: Never

  # OPTIONAL: Pin to specific node
  # Uncomment to run on a specific node:
  # nodeName: your-node-name

  # OPTIONAL: Use affinity for more flexible node selection
  # Uncomment and edit to constrain to specific nodes:
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #       - matchExpressions:
  #         - key: kubernetes.io/hostname
  #           operator: In
  #           values:
  #           - your-node-1
  #           - your-node-2

  # Node selector to ensure placement on GPU nodes
  nodeSelector:
    nvidia.com/gpu.present: "true"

  # Init container to auto-detect RDMA interfaces
  initContainers:
  - name: detect-rdma
    image: image-registry.openshift-image-registry.svc:5000/nccl-test/ml-dev-env:pytorch-2.9-numpy2
    command:
    - /bin/bash
    - -c
    - |
      set -e
      echo "Detecting RDMA interfaces..."

      # Detect InfiniBand devices
      if command -v ibv_devinfo &> /dev/null; then
        IB_DEVICES=$(ibv_devinfo -l 2>/dev/null | grep -v "^$" | tr '\n' ',' | sed 's/,$//' || echo "")
        if [ -n "$IB_DEVICES" ]; then
          echo "export NCCL_IB_HCA=\"$IB_DEVICES\"" >> /shared/nccl-env.sh
          echo "Detected IB devices: $IB_DEVICES"
        else
          echo "# No IB devices detected" >> /shared/nccl-env.sh
          echo "Warning: No IB devices found"
        fi
      else
        echo "# ibv_devinfo not available" >> /shared/nccl-env.sh
        echo "Warning: ibv_devinfo not available"
      fi

      # Detect RDMA network interfaces (net1, net2, etc.)
      RDMA_IFACES=$(ip -o link show | awk -F': ' '{print $2}' | grep -E '^net[0-9]+$' | tr '\n' ',' | sed 's/,$//' || echo "eth0")
      if [ -n "$RDMA_IFACES" ]; then
        echo "export NCCL_SOCKET_IFNAME=\"$RDMA_IFACES\"" >> /shared/nccl-env.sh
        echo "Detected RDMA interfaces: $RDMA_IFACES"
      else
        echo "export NCCL_SOCKET_IFNAME=\"eth0\"" >> /shared/nccl-env.sh
        echo "Warning: No RDMA interfaces found, using eth0"
      fi

      echo "RDMA detection complete"
      cat /shared/nccl-env.sh
    volumeMounts:
    - name: nccl-env
      mountPath: /shared
    securityContext:
      capabilities:
        add:
          - IPC_LOCK

  # Service account with nccl-rdma-scc for unlimited memlock
  serviceAccountName: default

  containers:
  - name: ml-dev
    image: image-registry.openshift-image-registry.svc:5000/nccl-test/ml-dev-env:pytorch-2.9-numpy2
    imagePullPolicy: Always

    # CUSTOMIZE: Change GPU count
    # Common options: 1, 2, 4, 8 (depending on node availability)
    resources:
      requests:
        nvidia.com/gpu: 4  # Default: 4 GPUs
        memory: 128Gi
        cpu: 32
      limits:
        nvidia.com/gpu: 4  # Must match requests
        memory: 256Gi
        cpu: 64

    # Security context for RDMA - SYS_RESOURCE allows setting unlimited memlock
    securityContext:
      capabilities:
        add:
          - IPC_LOCK
          - SYS_RESOURCE

    # Environment variables for multi-GPU and RDMA
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: "all"
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: "compute,utility"
    - name: NCCL_DEBUG
      value: "INFO"
    - name: NCCL_IB_DISABLE
      value: "0"
    # NCCL_IB_HCA: auto-detected by init container
    # NCCL_SOCKET_IFNAME: auto-detected by init container
    - name: NCCL_IB_GID_INDEX
      value: "3"
    - name: NCCL_NET_GDR_LEVEL
      value: "5"
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1,2,3"
    - name: OMP_NUM_THREADS
      value: "8"

    # Volume mounts
    volumeMounts:
    - name: workspace
      mountPath: /workspace
    - name: datasets
      mountPath: /datasets
    - name: nccl-env
      mountPath: /shared

    # Ports for services
    ports:
    - containerPort: 8080
      name: code-server
      protocol: TCP
    - containerPort: 8888
      name: jupyter
      protocol: TCP
    - containerPort: 6006
      name: tensorboard
      protocol: TCP

    # Startup command
    command:
    - /bin/bash
    - -c
    - |
      set -e

      # Set unlimited memlock for RDMA (works with SYS_RESOURCE capability)
      ulimit -l unlimited
      echo "Memlock limit: $(ulimit -l)"
      echo ""

      # Source auto-detected RDMA configuration
      if [ -f /shared/nccl-env.sh ]; then
        echo "Loading auto-detected RDMA configuration..."
        source /shared/nccl-env.sh
        echo "NCCL_IB_HCA=$NCCL_IB_HCA"
        echo "NCCL_SOCKET_IFNAME=$NCCL_SOCKET_IFNAME"
      else
        echo "Warning: /shared/nccl-env.sh not found, using defaults"
      fi
      echo ""

      # Show NCCL configuration
      echo "NCCL Configuration:"
      env | grep NCCL_ | sort
      echo ""

      # Start code-server in background
      code-server --bind-addr 0.0.0.0:8080 --auth none /workspace &

      # Keep container running
      tail -f /dev/null

  volumes:
  - name: workspace
    persistentVolumeClaim:
      claimName: ml-dev-workspace
  - name: datasets
    persistentVolumeClaim:
      claimName: ml-datasets
  - name: nccl-env
    emptyDir: {}

  # Tolerate GPU node taints
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
