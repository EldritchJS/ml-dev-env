apiVersion: v1
kind: Service
metadata:
  name: {app_name}-headless
  namespace: {namespace}
  labels:
    app: {app_name}-multi
spec:
  clusterIP: None  # Headless service for StatefulSet
  selector:
    app: {app_name}-multi
  ports:
  - port: 29500
    name: master
  - port: 8080
    name: code-server
  - port: 5678
    name: debug
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {app_name}
  namespace: {namespace}
  labels:
    app: {app_name}-multi
spec:
  serviceName: {app_name}-headless
  # CUSTOMIZE: Change replicas to set number of nodes (each node gets 1 pod)
  # Examples: 2 nodes = 8 GPUs, 4 nodes = 16 GPUs, 8 nodes = 32 GPUs
  replicas: 2  # Default: 2 nodes
  podManagementPolicy: Parallel  # Launch all pods simultaneously

  selector:
    matchLabels:
      app: {app_name}-multi

  template:
    metadata:
      labels:
        app: {app_name}-multi
        pytorch-version: "2.9"
        numpy-version: "2.2.6"

    spec:
      restartPolicy: Always

      # Spread pods across different nodes (one pod per node)
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - {app_name}-multi
            topologyKey: kubernetes.io/hostname

        # OPTIONAL: Constrain to specific nodes
        # Uncomment and edit to run on specific nodes:
        # nodeAffinity:
        #   requiredDuringSchedulingIgnoredDuringExecution:
        #     nodeSelectorTerms:
        #     - matchExpressions:
        #       - key: kubernetes.io/hostname
        #         operator: In
        #         values:
        #         - your-node-1
        #         - your-node-2
        #         - your-node-3

      # Node selector to ensure placement on GPU nodes
      nodeSelector:
        nvidia.com/gpu.present: "true"

      # Tolerate GPU node taints
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

      containers:
      - name: ml-dev
        image: image-registry.openshift-image-registry.svc:5000/nccl-test/ml-dev-env:pytorch-2.9-numpy2
        imagePullPolicy: Always

        # CUSTOMIZE: Change GPU count per pod
        # Total GPUs = replicas × GPUs per pod
        # Examples: 2 nodes × 4 GPUs = 8 total, 4 nodes × 8 GPUs = 32 total
        resources:
          requests:
            nvidia.com/gpu: 4  # Default: 4 GPUs per pod
            memory: 128Gi
            cpu: 32
          limits:
            nvidia.com/gpu: 4  # Must match requests
            memory: 256Gi
            cpu: 64

        # Security context (IPC_LOCK not required for TCP mode)
        securityContext:
          capabilities:
            add:
              - IPC_LOCK  # Optional, helps with shared memory

        # Environment variables for multi-GPU and multi-node
        env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"

        # NCCL configuration for multi-node (TCP/Ethernet - NO RDMA)
        - name: NCCL_DEBUG
          value: "INFO"
        # Disable InfiniBand/RDMA - use TCP sockets instead
        - name: NCCL_IB_DISABLE
          value: "1"
        # Use standard Ethernet interface (auto-detect or specify eth0)
        - name: NCCL_SOCKET_IFNAME
          value: "^lo,docker0"  # Exclude loopback and docker, use primary interface
        # Use TCP/IP for communication
        - name: NCCL_P2P_LEVEL
          value: "NVL"  # NVLink for intra-node, TCP for inter-node

        # Pod identity for DeepSpeed
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP

        # DeepSpeed master address (pod-0 is master)
        - name: MASTER_ADDR
          value: "{app_name}-0.{app_name}-headless.{namespace}.svc.cluster.local"
        - name: MASTER_PORT
          value: "29500"

        # CUSTOMIZE: Update WORLD_SIZE and GPUS_PER_NODE to match your configuration
        # WORLD_SIZE = replicas × GPUS_PER_NODE (total GPUs across all nodes)
        - name: WORLD_SIZE
          value: "8"  # Default: 2 nodes × 4 GPUs = 8 total
        - name: GPUS_PER_NODE
          value: "4"  # Default: 4 GPUs per node (must match nvidia.com/gpu above)

        # OpenMP threads
        - name: OMP_NUM_THREADS
          value: "8"

        # Volume mounts
        volumeMounts:
        - name: workspace
          mountPath: /workspace
        - name: datasets
          mountPath: /datasets
        - name: dshm
          mountPath: /dev/shm

        # Ports for services
        ports:
        - containerPort: 29500
          name: master
          protocol: TCP
        - containerPort: 8080
          name: code-server
          protocol: TCP
        - containerPort: 8888
          name: jupyter
          protocol: TCP
        - containerPort: 6006
          name: tensorboard
          protocol: TCP
        - containerPort: 5678
          name: debug
          protocol: TCP

        # Liveness probe
        livenessProbe:
          exec:
            command:
            - /bin/bash
            - -c
            - nvidia-smi
          initialDelaySeconds: 30
          periodSeconds: 30

        # Readiness probe
        readinessProbe:
          exec:
            command:
            - /bin/bash
            - -c
            - nvidia-smi && [ -d /workspace ]
          initialDelaySeconds: 10
          periodSeconds: 10

        # Startup command
        command:
        - /bin/bash
        - -c
        - |
          set -e

          # Calculate node rank from pod ordinal
          POD_ORDINAL=${HOSTNAME##*-}
          export NODE_RANK=$POD_ORDINAL

          echo "=========================================="
          echo "ML Dev Environment - Multi-Node DeepSpeed"
          echo "Network Mode: TCP/Ethernet (NO RDMA)"
          echo "=========================================="
          echo "Pod: $POD_NAME"
          echo "Node Rank: $NODE_RANK"
          echo "World Size: $WORLD_SIZE"
          echo "Master: $MASTER_ADDR:$MASTER_PORT"
          echo "NCCL: TCP sockets (IB disabled)"
          echo ""

          # Show GPU info
          nvidia-smi --query-gpu=index,name,memory.total --format=csv,noheader
          echo ""

          # Start code-server in background
          code-server --bind-addr 0.0.0.0:8080 --auth none /workspace &

          # Create hostfile for DeepSpeed dynamically
          mkdir -p /workspace/.deepspeed
          NUM_NODES=$((WORLD_SIZE / GPUS_PER_NODE))
          > /workspace/.deepspeed/hostfile
          for i in $(seq 0 $((NUM_NODES - 1))); do
            echo "{app_name}-$i.{app_name}-headless.{namespace}.svc.cluster.local slots=$GPUS_PER_NODE" >> /workspace/.deepspeed/hostfile
          done

          echo "Hostfile created at /workspace/.deepspeed/hostfile ($NUM_NODES nodes)"
          cat /workspace/.deepspeed/hostfile
          echo ""
          echo "Ready for multi-node training!"
          echo "=========================================="

          # Application startup
          {app_startup_code}

          # Keep container running
          tail -f /dev/null

      volumes:
      - name: workspace
        persistentVolumeClaim:
          claimName: ml-dev-workspace
      - name: datasets
        persistentVolumeClaim:
          claimName: ml-datasets
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 32Gi
