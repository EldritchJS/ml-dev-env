apiVersion: v1
kind: Service
metadata:
  name: h-kim-test-headless
  namespace: b-efficient-memory-offloading-765cab
  labels:
    app: h-kim-test-multi
spec:
  clusterIP: None  # Headless service
  selector:
    app: h-kim-test-multi
  ports:
  - port: 29500
    name: master
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: h-kim-test
  namespace: b-efficient-memory-offloading-765cab
  labels:
    app: h-kim-test-multi
spec:
  serviceName: h-kim-test-headless
  replicas: 2  # 2 nodes = 8 GPUs total
  podManagementPolicy: Parallel

  selector:
    matchLabels:
      app: h-kim-test-multi

  template:
    metadata:
      labels:
        app: h-kim-test-multi
      annotations:
        k8s.v1.cni.cncf.io/networks: b-efficient-memory-offloading-765cab/eno5np0-network, b-efficient-memory-offloading-765cab/eno6np0-network, b-efficient-memory-offloading-765cab/eno7np0-network, b-efficient-memory-offloading-765cab/eno8np0-network

    spec:
      restartPolicy: Always

      # Spread pods across different nodes (DIFFERENT from h-kim)
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - moc-r4pcc04u09-nairr
                - moc-r4pcc04u11-nairr
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - h-kim-test-multi
            topologyKey: kubernetes.io/hostname

      nodeSelector:
        nvidia.com/gpu.present: "true"

      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

      # Service account with nccl-rdma-scc for unlimited memlock
      serviceAccountName: h-kim-sa

      containers:
      - name: h-kim
        image: image-registry.openshift-image-registry.svc:5000/b-efficient-memory-offloading-765cab/h-kim:latest
        imagePullPolicy: Always

        # Security context for RDMA - SYS_RESOURCE allows setting unlimited memlock
        securityContext:
          capabilities:
            add:
              - IPC_LOCK
              - SYS_RESOURCE

        resources:
          requests:
            nvidia.com/gpu: 4
            memory: 1200Gi
            cpu: 32
            openshift.io/eno2np0rdma: 1
            openshift.io/eno3np1rdma: 1
            openshift.io/eno5np0rdma: 1
            openshift.io/eno6np0rdma: 1
          limits:
            nvidia.com/gpu: 4
            memory: 1200Gi
            cpu: 64
            openshift.io/eno2np0rdma: 1
            openshift.io/eno3np1rdma: 1
            openshift.io/eno5np0rdma: 1
            openshift.io/eno6np0rdma: 1

        env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"

        # NCCL configuration (all values auto-detected by init container)
        # Users can override any value by setting env vars here
        - name: NCCL_DEBUG
          value: "INFO"
        # All other NCCL values auto-detected:
        # - NCCL_IB_DISABLE (auto)
        # - NCCL_IB_HCA (auto)
        # - NCCL_SOCKET_IFNAME (auto)
        # - NCCL_IB_GID_INDEX (auto)
        # - NCCL_NET_GDR_LEVEL (auto)
        # - NCCL_P2P_LEVEL (auto)
        # - GPUS_PER_NODE (auto)
        # - OMP_NUM_THREADS (auto)

        # Pod identity
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP

        # Distributed training settings
        - name: MASTER_ADDR
          value: "h-kim-test-0.h-kim-test-headless.b-efficient-memory-offloading-765cab.svc.cluster.local"
        - name: MASTER_PORT
          value: "29500"
        - name: REPLICAS
          value: "2"  # Number of pods in StatefulSet
        # WORLD_SIZE calculated at runtime: replicas × GPUs per node
        # GPUS_PER_NODE: auto-detected by init container

        volumeMounts:
        - name: workspace
          mountPath: /workspace
        - name: dshm
          mountPath: /dev/shm
        - name: nccl-env
          mountPath: /shared

        ports:
        - containerPort: 29500
          name: master
          protocol: TCP

        command:
        - /bin/bash
        - -c
        - |
          set -e

          # Set unlimited memlock for RDMA (works with SYS_RESOURCE capability)
          ulimit -l unlimited
          echo "Memlock limit: $(ulimit -l)"
          echo ""

          # Re-run autodetect in main container (has access to RDMA devices)
          echo "=========================================="
          echo "Running NCCL Auto-Detection (Main Container)"
          echo "=========================================="
          /usr/local/bin/autodetect-nccl.sh
          echo ""

          # Source comprehensive auto-detected configuration
          if [ -f /shared/nccl-env.sh ]; then
            echo "=========================================="
            echo "Loading Auto-Detected Configuration"
            echo "=========================================="
            source /shared/nccl-env.sh
            echo ""
          else
            echo "ERROR: /shared/nccl-env.sh not found!"
            echo "Autodetect failed"
            exit 1
          fi

          # Calculate node rank from pod ordinal
          POD_ORDINAL=${HOSTNAME##*-}
          export NODE_RANK=$POD_ORDINAL

          # Calculate WORLD_SIZE from replicas × GPUs per node
          export WORLD_SIZE=$((REPLICAS * GPUS_PER_NODE))

          echo "=========================================="
          echo "H-Kim-Test Multi-Node Environment"
          echo "=========================================="
          echo "Pod: $POD_NAME"
          echo "Node Rank: $NODE_RANK"
          echo ""
          echo "AUTO-DETECTED VALUES:"
          echo "  GPUs per node: $GPUS_PER_NODE (detected!)"
          echo "  World size: $WORLD_SIZE (calculated: $REPLICAS × $GPUS_PER_NODE)"
          echo "  OMP threads: $OMP_NUM_THREADS (detected!)"
          echo "  Transport: $DETECTED_TRANSPORT (detected!)"
          echo ""
          echo "Master: $MASTER_ADDR:$MASTER_PORT"
          echo "=========================================="
          echo ""

          # Show comprehensive NCCL configuration
          echo "NCCL Configuration (auto-detected):"
          env | grep NCCL_ | sort
          echo ""

          # Show GPU topology
          echo "GPU Topology:"
          nvidia-smi topo -m 2>/dev/null || echo "  (topology info not available)"
          echo ""

          # Show detected GPUs
          echo "Detected GPUs:"
          nvidia-smi --query-gpu=index,name,memory.total --format=csv,noheader
          echo ""

          echo "Environment ready. Waiting for training job..."
          echo "To run training:"
          echo "  oc exec -it $POD_NAME -- bash"
          echo "  cd /workspace"
          echo "  torchrun --nproc_per_node=\$GPUS_PER_NODE train.py"
          echo ""

          sleep infinity

      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 32Gi
      - name: nccl-env
        emptyDir: {}

  # Each pod gets its own workspace PVC
  volumeClaimTemplates:
  - metadata:
      name: workspace
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
      storageClassName: ocs-external-storagecluster-ceph-rbd
