apiVersion: v1
kind: Pod
metadata:
  name: deepti-test
  namespace: nccl-test
  labels:
    app: deepti-test
    workload: qwen-omni
    pytorch-version: "2.9"
    numpy-version: "2.2.6"
spec:
  restartPolicy: Never

  # Node selector to ensure placement on GPU nodes
  nodeSelector:
    nvidia.com/gpu.present: "true"

  # Optional: Pin to specific node
  # Uncomment to run on specific Barcelona node
  # nodeName: moc-r4pcc04u25-nairr

  # Service account for permissions
  serviceAccountName: ml-dev-sa

  # Init container to auto-detect RDMA interfaces
  initContainers:
  - name: detect-rdma
    image: image-registry.openshift-image-registry.svc:5000/nccl-test/ml-dev-env:pytorch-2.9-numpy2
    command:
    - /bin/bash
    - -c
    - |
      set -e
      echo "Detecting RDMA interfaces..."

      # Detect InfiniBand devices
      if command -v ibv_devinfo &> /dev/null; then
        IB_DEVICES=$(ibv_devinfo -l 2>/dev/null | grep -v "^$" | tr '\n' ',' | sed 's/,$//' || echo "")
        if [ -n "$IB_DEVICES" ]; then
          echo "export NCCL_IB_HCA=\"$IB_DEVICES\"" >> /shared/nccl-env.sh
          echo "Detected IB devices: $IB_DEVICES"
        else
          echo "# No IB devices detected" >> /shared/nccl-env.sh
          echo "Warning: No IB devices found"
        fi
      else
        echo "# ibv_devinfo not available" >> /shared/nccl-env.sh
        echo "Warning: ibv_devinfo not available"
      fi

      # Detect RDMA network interfaces (net1, net2, net3, net4)
      RDMA_IFACES=$(ip -o link show | awk -F': ' '{print $2}' | grep -E '^net[0-9]+$' | tr '\n' ',' | sed 's/,$//' || echo "eth0")
      if [ -n "$RDMA_IFACES" ]; then
        echo "export NCCL_SOCKET_IFNAME=\"$RDMA_IFACES\"" >> /shared/nccl-env.sh
        echo "Detected RDMA interfaces: $RDMA_IFACES"
      else
        echo "export NCCL_SOCKET_IFNAME=\"eth0\"" >> /shared/nccl-env.sh
        echo "Warning: No RDMA interfaces found, using eth0"
      fi

      echo "RDMA detection complete"
      cat /shared/nccl-env.sh
    volumeMounts:
    - name: nccl-env
      mountPath: /shared

  containers:
  - name: qwen-omni
    image: image-registry.openshift-image-registry.svc:5000/nccl-test/ml-dev-env:pytorch-2.9-numpy2
    imagePullPolicy: Always

    # Request 4 GPUs (single node)
    resources:
      requests:
        nvidia.com/gpu: 4
        memory: 128Gi
        cpu: 32
      limits:
        nvidia.com/gpu: 4
        memory: 256Gi
        cpu: 64

    # Environment variables for multi-GPU (Barcelona cluster)
    env:
    - name: NVIDIA_VISIBLE_DEVICES
      value: "all"
    - name: NVIDIA_DRIVER_CAPABILITIES
      value: "compute,utility"
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1,2,3"
    - name: NCCL_DEBUG
      value: "INFO"
    # Barcelona has RDMA - enable InfiniBand (devices auto-detected)
    - name: NCCL_IB_DISABLE
      value: "0"
    # NCCL_IB_HCA: auto-detected by init container
    - name: NCCL_IB_GID_INDEX
      value: "3"
    - name: NCCL_NET_GDR_LEVEL
      value: "5"
    # NCCL_SOCKET_IFNAME: auto-detected by init container
    - name: NCCL_P2P_LEVEL
      value: "NVL"
    - name: OMP_NUM_THREADS
      value: "8"

    # Working directory
    workingDir: /workspace

    # Startup command
    command:
    - /bin/bash
    - -c
    - |
      set -e

      # Source auto-detected RDMA configuration
      if [ -f /shared/nccl-env.sh ]; then
        echo "Loading auto-detected RDMA configuration..."
        source /shared/nccl-env.sh
        echo "NCCL_IB_HCA=$NCCL_IB_HCA"
        echo "NCCL_SOCKET_IFNAME=$NCCL_SOCKET_IFNAME"
      else
        echo "Warning: /shared/nccl-env.sh not found, using defaults"
      fi
      echo ""

      echo "=========================================="
      echo "Qwen2.5-Omni Test (Barcelona Cluster)"
      echo "=========================================="
      echo ""

      # Show GPU information
      echo "GPU Information:"
      nvidia-smi --query-gpu=name,memory.total --format=csv,noheader
      echo ""

      echo "GPU Topology:"
      nvidia-smi topo -m
      echo ""

      # Show InfiniBand devices
      echo "InfiniBand Devices:"
      ibstat 2>/dev/null || echo "  (ibstat not available, but RDMA may still work)"
      echo ""

      # Verify qwen-omni-utils is installed
      echo "Verifying Python environment:"
      python -c "import torch; print(f'PyTorch {torch.__version__}, CUDA available: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}')"
      python -c "import transformers; print(f'Transformers {transformers.__version__}')"
      python -c "from qwen_omni_utils import process_mm_info; print('qwen-omni-utils: installed')"
      python -c "import flash_attn; print(f'flash-attn: {flash_attn.__version__}')"
      echo ""

      # Copy deepti.py from ConfigMap to workspace
      if [ -f /config/deepti.py ]; then
        cp /config/deepti.py /workspace/deepti.py
        echo "Copied deepti.py to workspace"
      else
        echo "ERROR: deepti.py not found in ConfigMap"
        exit 1
      fi

      echo "=========================================="
      echo "Running deepti.py..."
      echo "=========================================="
      echo ""

      # Run the test script
      cd /workspace
      python deepti.py

      echo ""
      echo "=========================================="
      echo "Test completed successfully!"
      echo "=========================================="

    # Volume mounts
    volumeMounts:
    - name: deepti-script
      mountPath: /config
      readOnly: true
    - name: nccl-env
      mountPath: /shared

  volumes:
  - name: deepti-script
    configMap:
      name: deepti-script
  - name: nccl-env
    emptyDir: {}

  # Tolerate GPU node taints
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
